{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "class CarTextTransformation(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, language='english'):\n",
        "        self.vocab = set()\n",
        "        self.stopwords = set(stopwords.words(language))\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        for doc in X:\n",
        "            # Convert document to lowercase and tokenize into words\n",
        "            words = word_tokenize(doc.lower())\n",
        "            # Remove stopwords and non-alphabetic characters\n",
        "            words = [w for w in words if w not in self.stopwords and w.isalpha()]\n",
        "            # Update vocabulary with unique words in document\n",
        "            self.vocab.update(words)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        transformed_X = []\n",
        "        for doc in X:\n",
        "            # Convert document to lowercase and tokenize into words\n",
        "            words = word_tokenize(doc.lower())\n",
        "            # Remove stopwords and non-alphabetic characters\n",
        "            words = [w for w in words if w not in self.stopwords and w.isalpha()]\n",
        "            # Count occurrences of each word in document\n",
        "            word_counts = Counter(words)\n",
        "            # Create document index dictionary\n",
        "            doc_index = {w: word_counts[w] for w in self.vocab}\n",
        "            # Add document index to transformed_X\n",
        "            transformed_X.append(doc_index)\n",
        "        return transformed_X\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create instance of CarTextTransformation\n",
        "    transformer = CarTextTransformation()\n",
        "\n",
        "    # Define example car text\n",
        "    car_text = ['La voiture est noire et spacieuse.','Le bateau est blanc et rapide.','il y a deux voiture jeep rouges']\n",
        "\n",
        "\n",
        "    # Transform car text into BoW vectors\n",
        "    transformer.fit(car_text)\n",
        "    bow_vectors = transformer.transform(car_text)\n",
        "\n",
        "    # Print BoW vectors\n",
        "    print(bow_vectors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1rgyrM5L7VK",
        "outputId": "b3253172-631a-41b2-9dfa-500465701d93"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'bateau': 0, 'noire': 1, 'deux': 0, 'il': 0, 'blanc': 0, 'spacieuse': 1, 'jeep': 0, 'est': 1, 'et': 1, 'le': 0, 'la': 1, 'voiture': 1, 'rapide': 0, 'rouges': 0}, {'bateau': 1, 'noire': 0, 'deux': 0, 'il': 0, 'blanc': 1, 'spacieuse': 0, 'jeep': 0, 'est': 1, 'et': 1, 'le': 1, 'la': 0, 'voiture': 0, 'rapide': 1, 'rouges': 0}, {'bateau': 0, 'noire': 0, 'deux': 1, 'il': 1, 'blanc': 0, 'spacieuse': 0, 'jeep': 1, 'est': 0, 'et': 0, 'le': 0, 'la': 0, 'voiture': 1, 'rapide': 0, 'rouges': 1}]\n"
          ]
        }
      ]
    }
  ]
}